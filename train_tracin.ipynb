{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 根据tracin_xxx得到的TXT文件，对模型进行训练，并保存数据到tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "from torchvision import transforms\n",
    "import my_dataset\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from models.vit import ViT\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models_DLA.dla_simple import SimpleDLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 选取训练数据\n",
    "\n",
    "$$\n",
    "Train_{tracin} = \\sum_{i = 0}({Train_{sorted}}[Segment[i].head:Segment[i].rear]).Sample(Segment[i].sample)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 从第cp*10个checkpoint开始训练\n",
    "cp = 2\n",
    "\n",
    "segments = [\n",
    "    [0, 8000, 7000],\n",
    "    [8000, 15000, 2500],\n",
    "    [33000, 35000, 1000]\n",
    "]\n",
    "\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 读取训练数据和测试数据，其中tracin_file2文件夹中的文件是根据tracin进行排序后的\n",
    "train_data = utils.read_file(\"./train_result_DLA/forget/easy_\" + str(cp) + \"0.txt\")\n",
    "val_data = utils.read_file(\"../cifar10/test_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:20*TOTAL:10500*[0--8000]->7000&[8000--15000]->2500&[33000--35000]->1000_E_F\n"
     ]
    }
   ],
   "source": [
    "# 根据segment得到训练数据\n",
    "train_data_tracin = []\n",
    "\n",
    "for i, segment in enumerate(segments):\n",
    "    train_data_tracin += utils.split_easy_hard_num(train_data, segment[0], segment[1],segment[2])\n",
    "\n",
    "# index = np.zeros(len(train_data_tracin))\n",
    "# y = np.ones(len(train_data_tracin))\n",
    "# for i2, data in enumerate(train_data_tracin):\n",
    "#     index[i2] = train_data.index(data)\n",
    "# plt.figure(figsize=(3,15),dpi=100)\n",
    "# color = [plt.get_cmap(\"Spectral\", len(train_data))(int (i)) for i in index]\n",
    "# plt.scatter(y, index, s = 0.1, c = color)\n",
    "# plt.xticks([]) \n",
    "# plt.ylim((0,len(train_data)))\n",
    "# plt.colorbar()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "train_data = train_data_tracin\n",
    "    \n",
    "description = \"EPOCH:\" + str(cp*10) + utils.get_description(train_data, segments) + \"_E_F\"\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "writer = SummaryWriter(log_dir = 'logs_forget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 dataloader workers every process\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "print('Using {} dataloader workers every process'.format(nw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x400 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制train_data的分布情况\n",
    "utils.draw_hist(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 定义data_transform，和正常训练时保持一致\n",
    "data_transform = {\n",
    "        \"train\": transforms.Compose([\n",
    "                                    transforms.RandomCrop(32, padding=4),\n",
    "                                    transforms.Resize(32),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]),\n",
    "        \"val\": transforms.Compose([transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])}\n",
    "\n",
    "\n",
    "# 定义dataset\n",
    "train_dataset = my_dataset.MyDataSet_CIFAR_Tracin(images_path=train_data,\n",
    "                        transform=data_transform[\"train\"])\n",
    "\n",
    "val_dataset = my_dataset.MyDataSet_CIFAR_Tracin(images_path=val_data,\n",
    "                        transform=data_transform[\"val\"])\n",
    "\n",
    "\n",
    "# 定义DataLoader类\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=nw,\n",
    "                                            collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=nw,\n",
    "                                            collate_fn=val_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "10560"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "# model = ViT(\n",
    "#     image_size = 32,\n",
    "#     patch_size = 4,\n",
    "#     num_classes = 10,\n",
    "#     dim = 512,\n",
    "#     depth = 6,\n",
    "#     heads = 8,\n",
    "#     mlp_dim = 512,\n",
    "#     dropout = 0.1,\n",
    "#     emb_dropout = 0.1\n",
    "# ).to(device)\n",
    "\n",
    "model = SimpleDLA().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 定义损失函数和potimizer\n",
    "# loss_function = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1,\n",
    "                      momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "SimpleDLA(\n  (base): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n  )\n  (layer1): Sequential(\n    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n  )\n  (layer2): Sequential(\n    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n  )\n  (layer3): Tree(\n    (root): Root(\n      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (left_tree): BasicBlock(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (right_tree): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer4): Tree(\n    (root): Root(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (left_tree): Tree(\n      (root): Root(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (left_tree): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (shortcut): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (right_tree): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (shortcut): Sequential()\n      )\n    )\n    (right_tree): Tree(\n      (root): Root(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (left_tree): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (shortcut): Sequential()\n      )\n      (right_tree): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (shortcut): Sequential()\n      )\n    )\n  )\n  (layer5): Tree(\n    (root): Root(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (left_tree): Tree(\n      (root): Root(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (left_tree): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (shortcut): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (right_tree): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (shortcut): Sequential()\n      )\n    )\n    (right_tree): Tree(\n      (root): Root(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (left_tree): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (shortcut): Sequential()\n      )\n      (right_tree): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (shortcut): Sequential()\n      )\n    )\n  )\n  (layer6): Tree(\n    (root): Root(\n      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (left_tree): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (right_tree): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (linear): Linear(in_features=512, out_features=10, bias=True)\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载第 cp*10个checkpoint\n",
    "checkpoint = torch.load('./weights_LDA/checkpoint-' + str(cp*10) + '.pth.tar')\n",
    "    \n",
    "model.load_state_dict(checkpoint['state_dict']) \n",
    "optimizer.load_state_dict(checkpoint['optimizer']) #加载优化器的参数\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 20] loss: 0.789, acc: 0.726: 100%|██████████| 79/79 [00:02<00:00, 34.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.7262\n",
      "Best model is saved! Accuracy is 0.7364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 25] loss: 0.929, acc: 0.699: 100%|██████████| 79/79 [00:02<00:00, 36.14it/s]\n",
      "[valid epoch 30] loss: 0.954, acc: 0.695: 100%|██████████| 79/79 [00:02<00:00, 36.13it/s]\n",
      "[valid epoch 35] loss: 0.807, acc: 0.731: 100%|██████████| 79/79 [00:02<00:00, 35.54it/s]\n",
      "[valid epoch 40] loss: 0.865, acc: 0.709: 100%|██████████| 79/79 [00:02<00:00, 35.58it/s]\n",
      "[valid epoch 45] loss: 0.856, acc: 0.725: 100%|██████████| 79/79 [00:02<00:00, 35.60it/s]\n",
      "[valid epoch 50] loss: 0.901, acc: 0.716: 100%|██████████| 79/79 [00:02<00:00, 34.12it/s]\n",
      "[valid epoch 55] loss: 1.298, acc: 0.646: 100%|██████████| 79/79 [00:02<00:00, 35.25it/s]\n",
      "[valid epoch 60] loss: 0.895, acc: 0.718: 100%|██████████| 79/79 [00:02<00:00, 35.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.7392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 65] loss: 0.803, acc: 0.740: 100%|██████████| 79/79 [00:02<00:00, 34.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.7398\n",
      "Best model is saved! Accuracy is 0.7456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 70] loss: 0.886, acc: 0.728: 100%|██████████| 79/79 [00:02<00:00, 35.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.7578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 75] loss: 0.948, acc: 0.704: 100%|██████████| 79/79 [00:02<00:00, 35.00it/s]\n",
      "[valid epoch 80] loss: 0.775, acc: 0.756: 100%|██████████| 79/79 [00:02<00:00, 35.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.7598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 85] loss: 1.484, acc: 0.590: 100%|██████████| 79/79 [00:02<00:00, 35.01it/s]\n",
      "[valid epoch 90] loss: 0.858, acc: 0.731: 100%|██████████| 79/79 [00:02<00:00, 34.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.7822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 95] loss: 0.848, acc: 0.736: 100%|██████████| 79/79 [00:02<00:00, 35.21it/s]\n",
      "[valid epoch 100] loss: 0.815, acc: 0.755: 100%|██████████| 79/79 [00:02<00:00, 34.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.7826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 105] loss: 0.859, acc: 0.740: 100%|██████████| 79/79 [00:02<00:00, 35.43it/s]\n",
      "[valid epoch 110] loss: 0.641, acc: 0.793: 100%|██████████| 79/79 [00:02<00:00, 34.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.7934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 115] loss: 0.656, acc: 0.801: 100%|██████████| 79/79 [00:02<00:00, 34.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 120] loss: 0.998, acc: 0.733: 100%|██████████| 79/79 [00:02<00:00, 34.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.8046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 125] loss: 0.864, acc: 0.747: 100%|██████████| 79/79 [00:02<00:00, 35.11it/s]\n",
      "[valid epoch 130] loss: 0.756, acc: 0.785: 100%|██████████| 79/79 [00:02<00:00, 35.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 135] loss: 0.739, acc: 0.785: 100%|██████████| 79/79 [00:02<00:00, 35.11it/s]\n",
      "[valid epoch 140] loss: 0.745, acc: 0.792: 100%|██████████| 79/79 [00:02<00:00, 33.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.8108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 145] loss: 0.701, acc: 0.792: 100%|██████████| 79/79 [00:02<00:00, 34.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.8148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 150] loss: 0.720, acc: 0.805: 100%|██████████| 79/79 [00:02<00:00, 34.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.8264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 155] loss: 0.726, acc: 0.817: 100%|██████████| 79/79 [00:02<00:00, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.8406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 160] loss: 0.759, acc: 0.826: 100%|██████████| 79/79 [00:02<00:00, 35.36it/s]\n",
      "[valid epoch 165] loss: 0.662, acc: 0.838: 100%|██████████| 79/79 [00:02<00:00, 35.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.8406\n",
      "Best model is saved! Accuracy is 0.8478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 170] loss: 0.640, acc: 0.840: 100%|██████████| 79/79 [00:02<00:00, 35.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 175] loss: 0.687, acc: 0.837: 100%|██████████| 79/79 [00:02<00:00, 35.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.8562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 180] loss: 0.660, acc: 0.847: 100%|██████████| 79/79 [00:02<00:00, 34.74it/s]\n",
      "[valid epoch 185] loss: 0.625, acc: 0.856: 100%|██████████| 79/79 [00:02<00:00, 35.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.8564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 190] loss: 0.644, acc: 0.851: 100%|██████████| 79/79 [00:02<00:00, 34.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.8578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 195] loss: 0.652, acc: 0.853: 100%|██████████| 79/79 [00:02<00:00, 35.64it/s]\n",
      "[valid epoch 200] loss: 0.635, acc: 0.855: 100%|██████████| 79/79 [00:02<00:00, 35.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 205] loss: 0.670, acc: 0.853: 100%|██████████| 79/79 [00:02<00:00, 35.05it/s]\n",
      "[valid epoch 210] loss: 0.653, acc: 0.855: 100%|██████████| 79/79 [00:02<00:00, 34.86it/s]\n",
      "[valid epoch 215] loss: 0.633, acc: 0.856: 100%|██████████| 79/79 [00:02<00:00, 35.22it/s]\n",
      "[valid epoch 220] loss: 0.648, acc: 0.857: 100%|██████████| 79/79 [00:02<00:00, 35.59it/s]\n",
      "[valid epoch 225] loss: 0.631, acc: 0.858: 100%|██████████| 79/79 [00:02<00:00, 35.89it/s]\n",
      "[valid epoch 230] loss: 0.625, acc: 0.859: 100%|██████████| 79/79 [00:02<00:00, 35.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is saved! Accuracy is 0.8606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid epoch 235] loss: 0.628, acc: 0.856: 100%|██████████| 79/79 [00:02<00:00, 34.83it/s]\n",
      "[valid epoch 240] loss: 0.643, acc: 0.854: 100%|██████████| 79/79 [00:02<00:00, 35.72it/s]\n",
      "[valid epoch 245] loss: 0.656, acc: 0.849: 100%|██████████| 79/79 [00:02<00:00, 35.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# 训练（300 - 10*cp）个epoch\n",
    "for epoch in range(250 - 10 * cp):\n",
    "    \n",
    "    model.train()\n",
    "    accu_loss = torch.zeros(1).to(device)  # 累计损失\n",
    "    accu_num = torch.zeros(1).to(device)  # 累计预测正确的样本数\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    sample_num = 0\n",
    "    # data_loader = tqdm(train_loader)\n",
    "    # 训练\n",
    "    for step, data in enumerate(train_loader):\n",
    "        images, labels, n = data\n",
    "\n",
    "        sample_num += images.shape[0]\n",
    "\n",
    "        pred = model(images.to(device))\n",
    "        \n",
    "        pred_classes = torch.max(pred, dim=1)[1]  # 预测的类别，[1]是标签索引\n",
    "       \n",
    "        \n",
    "        accu_num += torch.eq(pred_classes, labels.to(device)).sum()\n",
    "        loss = loss_function(pred, labels.to(device))\n",
    "        loss.backward()\n",
    "        \n",
    "        accu_loss += loss.detach()\n",
    "        \n",
    "        # data_loader.desc = \"[train epoch {}] loss: {:.3f}, acc: {:.3f}\".format(epoch  + 10 * cp,\n",
    "        #                                                                        accu_loss.item() / (step + 1),\n",
    "        #                                                                        accu_num.item() / sample_num)\n",
    "        optimizer.step()  # 更新\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # 进行evaluate\n",
    "    train_loss =  accu_loss.item() / (step + 1)\n",
    "    train_acc = accu_num.item() / sample_num\n",
    "    val_loss, val_acc = utils.evaluate(model=model,\n",
    "                                data_loader=val_loader,\n",
    "                                device=device,\n",
    "                                epoch=epoch + 10 * cp,\n",
    "                                print_info=(epoch%5==0))\n",
    "    \n",
    "    # 将每个epoch的数据保存到tensorboard\n",
    "    writer.add_scalar(tags[0] + \"_\"+ description, train_loss, epoch + 10 * cp)\n",
    "    # writer.add_scalar(tags[1] + \"_\" + str(cp*10) + description, train_acc, epoch + 10 * cp)\n",
    "    writer.add_scalar(tags[2] + \"_\"+ description, val_loss, epoch + 10 * cp)\n",
    "    writer.add_scalar(tags[3] + \"_\"+ description, val_acc, epoch + 10 * cp)\n",
    "    # writer.add_scalar(tags[4] + \"_\" + str(cp*10) + description, optimizer.param_groups[0][\"lr\"], epoch + 10 * cp)\n",
    "    if val_acc >= best_acc:\n",
    "        best_acc = val_acc\n",
    "        \n",
    "        state = {\n",
    "                    'epoch' : epoch + 1,  #保存当前的迭代次数\n",
    "                    'state_dict' : model.state_dict(), #保存模型参数\n",
    "                    'optimizer' : optimizer.state_dict()\n",
    "                }\n",
    "\n",
    "        torch.save(state, './best_model/' + description + '.pth.tar') \n",
    "        print(\"Best model is saved! Accuracy is {}\".format(best_acc))\n",
    "        \n",
    "        \n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac2c9fc71220d1b58b3640599b1e22027da1326aa67720425adf09ad6c638495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}