{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "from torchvision import transforms\n",
    "import my_dataset\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from models.vit import ViT\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from models_DLA.dla_simple import SimpleDLA\n",
    "from models import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "size = 64\n",
    "lr = 0.1\n",
    "epochs = 230\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# writer = SummaryWriter(log_dir = 'logs_LDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = utils.read_file(\"../cifar10/train_data.txt\")\n",
    "val_data = utils.read_file(\"../cifar10/val_data.txt\")\n",
    "test_data = utils.read_file(\"../cifar10/test_data.txt\")\n",
    "\n",
    "import random\n",
    "train_data = random.sample(train_data, 10500)\n",
    "\n",
    "\n",
    "data_transform = {\n",
    "        \"train\": transforms.Compose([\n",
    "                                    transforms.RandomCrop(32, padding=4),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.5, 0.5, 0.5], [0.2, 0.2, 0.2])]),\n",
    "        \"val\": transforms.Compose([transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.5, 0.5, 0.5], [0.2, 0.2, 0.2])])}\n",
    "train_dataset = my_dataset.MyDataSet_CIFAR_Tracin(images_path=train_data,\n",
    "                        transform=data_transform[\"train\"])\n",
    "\n",
    "val_dataset = my_dataset.MyDataSet_CIFAR_Tracin(images_path=val_data,\n",
    "                        transform=data_transform[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 dataloader workers every process\n"
     ]
    }
   ],
   "source": [
    "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "print('Using {} dataloader workers every process'.format(nw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=nw,\n",
    "                                            collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=nw,\n",
    "                                            collate_fn=val_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = ViT(\n",
    "#     image_size = size,\n",
    "#     patch_size = 4,\n",
    "#     num_classes = 10,\n",
    "#     dim = 512,\n",
    "#     depth = 6,\n",
    "#     heads = 8,\n",
    "#     mlp_dim = 512,\n",
    "#     dropout = 0.1,\n",
    "#     emb_dropout = 0.1\n",
    "# ).to(device)\n",
    "\n",
    "# model = SimpleDLA().to(device)\n",
    "model = ResNet18().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# input = torch.randn(1, 3, 32, 32).to(device)\n",
    "# writer.add_graph(model, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tags = [\"train_loss2\", \"train_acc2\", \"val_loss2\", \"val_acc2\", \"learning_rate2\"]\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[train epoch 0] loss: 2.406, acc: 0.182: 100%|██████████| 329/329 [00:11<00:00, 29.03it/s]\n",
      "[valid epoch 0] loss: 1.989, acc: 0.255: 100%|██████████| 313/313 [00:03<00:00, 87.91it/s] \n",
      "[train epoch 1] loss: 1.956, acc: 0.268: 100%|██████████| 329/329 [00:10<00:00, 32.49it/s]\n",
      "[valid epoch 1] loss: 1.809, acc: 0.342: 100%|██████████| 313/313 [00:03<00:00, 94.01it/s] \n",
      "[train epoch 2] loss: 1.851, acc: 0.314: 100%|██████████| 329/329 [00:10<00:00, 32.65it/s]\n",
      "[valid epoch 2] loss: 1.743, acc: 0.357: 100%|██████████| 313/313 [00:03<00:00, 96.00it/s] \n",
      "[train epoch 3] loss: 1.784, acc: 0.344: 100%|██████████| 329/329 [00:10<00:00, 32.64it/s]\n",
      "[valid epoch 3] loss: 1.749, acc: 0.357: 100%|██████████| 313/313 [00:03<00:00, 96.17it/s] \n",
      "[train epoch 4] loss: 1.699, acc: 0.374: 100%|██████████| 329/329 [00:10<00:00, 32.31it/s]\n",
      "[valid epoch 4] loss: 1.770, acc: 0.366: 100%|██████████| 313/313 [00:03<00:00, 89.85it/s] \n",
      "[train epoch 5] loss: 1.646, acc: 0.393: 100%|██████████| 329/329 [00:10<00:00, 31.87it/s]\n",
      "[valid epoch 5] loss: 1.527, acc: 0.445: 100%|██████████| 313/313 [00:03<00:00, 94.14it/s] \n",
      "[train epoch 6] loss: 1.545, acc: 0.432: 100%|██████████| 329/329 [00:10<00:00, 32.56it/s]\n",
      "[valid epoch 6] loss: 1.418, acc: 0.468: 100%|██████████| 313/313 [00:03<00:00, 95.95it/s] \n",
      "[train epoch 7] loss: 1.462, acc: 0.463: 100%|██████████| 329/329 [00:10<00:00, 32.35it/s]\n",
      "[valid epoch 7] loss: 1.507, acc: 0.488: 100%|██████████| 313/313 [00:03<00:00, 93.28it/s] \n",
      "[train epoch 8] loss: 1.373, acc: 0.505: 100%|██████████| 329/329 [00:10<00:00, 32.53it/s]\n",
      "[valid epoch 8] loss: 1.267, acc: 0.540: 100%|██████████| 313/313 [00:03<00:00, 96.11it/s] \n",
      "[train epoch 9] loss: 1.257, acc: 0.551: 100%|██████████| 329/329 [00:10<00:00, 32.50it/s]\n",
      "[valid epoch 9] loss: 1.187, acc: 0.581: 100%|██████████| 313/313 [00:03<00:00, 95.86it/s] \n",
      "[train epoch 10] loss: 1.190, acc: 0.574: 100%|██████████| 329/329 [00:10<00:00, 32.53it/s]\n",
      "[valid epoch 10] loss: 1.356, acc: 0.528: 100%|██████████| 313/313 [00:03<00:00, 88.48it/s] \n",
      "[train epoch 11] loss: 1.147, acc: 0.592: 100%|██████████| 329/329 [00:10<00:00, 32.17it/s]\n",
      "[valid epoch 11] loss: 1.185, acc: 0.585: 100%|██████████| 313/313 [00:03<00:00, 94.77it/s] \n",
      "[train epoch 12] loss: 1.091, acc: 0.613: 100%|██████████| 329/329 [00:10<00:00, 32.36it/s]\n",
      "[valid epoch 12] loss: 1.294, acc: 0.549: 100%|██████████| 313/313 [00:03<00:00, 94.46it/s] \n",
      "[train epoch 13] loss: 1.050, acc: 0.627: 100%|██████████| 329/329 [00:10<00:00, 31.80it/s]\n",
      "[valid epoch 13] loss: 1.227, acc: 0.602: 100%|██████████| 313/313 [00:03<00:00, 90.73it/s] \n",
      "[train epoch 14] loss: 0.999, acc: 0.648: 100%|██████████| 329/329 [00:10<00:00, 32.42it/s]\n",
      "[valid epoch 14] loss: 1.120, acc: 0.619: 100%|██████████| 313/313 [00:03<00:00, 95.58it/s] \n",
      "[train epoch 15] loss: 0.962, acc: 0.659: 100%|██████████| 329/329 [00:10<00:00, 32.36it/s]\n",
      "[valid epoch 15] loss: 1.455, acc: 0.550: 100%|██████████| 313/313 [00:03<00:00, 95.30it/s] \n",
      "[train epoch 16] loss: 0.913, acc: 0.682: 100%|██████████| 329/329 [00:10<00:00, 32.41it/s]\n",
      "[valid epoch 16] loss: 1.153, acc: 0.612: 100%|██████████| 313/313 [00:03<00:00, 95.06it/s] \n",
      "[train epoch 17] loss: 0.894, acc: 0.688: 100%|██████████| 329/329 [00:10<00:00, 32.39it/s]\n",
      "[valid epoch 17] loss: 1.106, acc: 0.637: 100%|██████████| 313/313 [00:03<00:00, 90.59it/s] \n",
      "[train epoch 18] loss: 0.875, acc: 0.696: 100%|██████████| 329/329 [00:10<00:00, 32.30it/s]\n",
      "[valid epoch 18] loss: 1.341, acc: 0.579: 100%|██████████| 313/313 [00:03<00:00, 95.03it/s] \n",
      "[train epoch 19] loss: 0.858, acc: 0.699: 100%|██████████| 329/329 [00:10<00:00, 32.34it/s]\n",
      "[valid epoch 19] loss: 1.327, acc: 0.588: 100%|██████████| 313/313 [00:03<00:00, 95.40it/s] \n",
      "[train epoch 20] loss: 0.829, acc: 0.710: 100%|██████████| 329/329 [00:10<00:00, 32.36it/s]\n",
      "[valid epoch 20] loss: 0.991, acc: 0.653: 100%|██████████| 313/313 [00:03<00:00, 95.38it/s] \n",
      "[train epoch 21] loss: 0.812, acc: 0.714: 100%|██████████| 329/329 [00:10<00:00, 31.92it/s]\n",
      "[valid epoch 21] loss: 0.839, acc: 0.712: 100%|██████████| 313/313 [00:03<00:00, 93.05it/s] \n",
      "[train epoch 22] loss: 0.795, acc: 0.727: 100%|██████████| 329/329 [00:10<00:00, 32.23it/s]\n",
      "[valid epoch 22] loss: 0.820, acc: 0.714: 100%|██████████| 313/313 [00:03<00:00, 90.38it/s] \n",
      "[train epoch 23] loss: 0.797, acc: 0.724: 100%|██████████| 329/329 [00:10<00:00, 32.27it/s]\n",
      "[valid epoch 23] loss: 0.927, acc: 0.684: 100%|██████████| 313/313 [00:03<00:00, 95.20it/s] \n",
      "[train epoch 24] loss: 0.771, acc: 0.728: 100%|██████████| 329/329 [00:10<00:00, 32.19it/s]\n",
      "[valid epoch 24] loss: 1.060, acc: 0.662: 100%|██████████| 313/313 [00:03<00:00, 93.61it/s] \n",
      "[train epoch 25] loss: 0.764, acc: 0.736: 100%|██████████| 329/329 [00:10<00:00, 32.23it/s]\n",
      "[valid epoch 25] loss: 0.961, acc: 0.705: 100%|██████████| 313/313 [00:03<00:00, 94.84it/s] \n",
      "[train epoch 26] loss: 0.768, acc: 0.734: 100%|██████████| 329/329 [00:10<00:00, 32.23it/s]\n",
      "[valid epoch 26] loss: 0.998, acc: 0.681: 100%|██████████| 313/313 [00:03<00:00, 94.89it/s] \n",
      "[train epoch 27] loss: 0.758, acc: 0.736: 100%|██████████| 329/329 [00:10<00:00, 32.19it/s]\n",
      "[valid epoch 27] loss: 0.856, acc: 0.709: 100%|██████████| 313/313 [00:03<00:00, 88.73it/s] \n",
      "[train epoch 28] loss: 0.748, acc: 0.743: 100%|██████████| 329/329 [00:10<00:00, 32.21it/s]\n",
      "[valid epoch 28] loss: 1.464, acc: 0.564: 100%|██████████| 313/313 [00:03<00:00, 94.27it/s] \n",
      "[train epoch 29] loss: 0.724, acc: 0.753: 100%|██████████| 329/329 [00:10<00:00, 32.18it/s]\n",
      "[valid epoch 29] loss: 1.193, acc: 0.648: 100%|██████████| 313/313 [00:03<00:00, 94.44it/s] \n",
      "[train epoch 30] loss: 0.720, acc: 0.749: 100%|██████████| 329/329 [00:10<00:00, 32.23it/s]\n",
      "[valid epoch 30] loss: 0.958, acc: 0.679: 100%|██████████| 313/313 [00:03<00:00, 94.63it/s] \n",
      "[train epoch 31] loss: 0.722, acc: 0.747: 100%|██████████| 329/329 [00:10<00:00, 32.17it/s]\n",
      "[valid epoch 31] loss: 0.827, acc: 0.723: 100%|██████████| 313/313 [00:03<00:00, 94.60it/s] \n",
      "[train epoch 32] loss: 0.706, acc: 0.750: 100%|██████████| 329/329 [00:10<00:00, 32.18it/s]\n",
      "[valid epoch 32] loss: 0.883, acc: 0.707: 100%|██████████| 313/313 [00:03<00:00, 94.26it/s] \n",
      "[train epoch 33] loss: 0.701, acc: 0.758: 100%|██████████| 329/329 [00:10<00:00, 32.15it/s]\n",
      "[valid epoch 33] loss: 0.969, acc: 0.683: 100%|██████████| 313/313 [00:03<00:00, 94.26it/s] \n",
      "[train epoch 34] loss: 0.713, acc: 0.756: 100%|██████████| 329/329 [00:10<00:00, 32.17it/s]\n",
      "[valid epoch 34] loss: 1.059, acc: 0.658: 100%|██████████| 313/313 [00:03<00:00, 88.58it/s] \n",
      "[train epoch 35] loss: 0.702, acc: 0.759: 100%|██████████| 329/329 [00:10<00:00, 32.14it/s]\n",
      "[valid epoch 35] loss: 0.812, acc: 0.726: 100%|██████████| 313/313 [00:03<00:00, 94.49it/s] \n",
      "[train epoch 36] loss: 0.690, acc: 0.760: 100%|██████████| 329/329 [00:10<00:00, 32.20it/s]\n",
      "[valid epoch 36] loss: 0.859, acc: 0.708: 100%|██████████| 313/313 [00:03<00:00, 93.98it/s] \n",
      "[train epoch 37] loss: 0.673, acc: 0.766: 100%|██████████| 329/329 [00:10<00:00, 32.06it/s]\n",
      "[valid epoch 37] loss: 0.750, acc: 0.747: 100%|██████████| 313/313 [00:03<00:00, 94.27it/s] \n",
      "[train epoch 38] loss: 0.674, acc: 0.766: 100%|██████████| 329/329 [00:10<00:00, 32.15it/s]\n",
      "[valid epoch 38] loss: 0.966, acc: 0.699: 100%|██████████| 313/313 [00:03<00:00, 94.48it/s] \n",
      "[train epoch 39] loss: 0.650, acc: 0.775: 100%|██████████| 329/329 [00:10<00:00, 32.06it/s]\n",
      "[valid epoch 39] loss: 1.139, acc: 0.659: 100%|██████████| 313/313 [00:03<00:00, 94.51it/s] \n",
      "[train epoch 40] loss: 0.661, acc: 0.769: 100%|██████████| 329/329 [00:10<00:00, 32.11it/s]\n",
      "[valid epoch 40] loss: 0.886, acc: 0.707: 100%|██████████| 313/313 [00:03<00:00, 93.94it/s] \n",
      "[train epoch 41] loss: 0.657, acc: 0.768: 100%|██████████| 329/329 [00:10<00:00, 32.02it/s]\n",
      "[valid epoch 41] loss: 0.845, acc: 0.733: 100%|██████████| 313/313 [00:03<00:00, 86.93it/s] \n",
      "[train epoch 42] loss: 0.661, acc: 0.771: 100%|██████████| 329/329 [00:10<00:00, 32.05it/s]\n",
      "[valid epoch 42] loss: 0.883, acc: 0.702: 100%|██████████| 313/313 [00:03<00:00, 93.91it/s] \n",
      "[train epoch 43] loss: 0.644, acc: 0.775: 100%|██████████| 329/329 [00:10<00:00, 32.09it/s]\n",
      "[valid epoch 43] loss: 0.929, acc: 0.707: 100%|██████████| 313/313 [00:03<00:00, 94.33it/s] \n",
      "[train epoch 44] loss: 0.647, acc: 0.777: 100%|██████████| 329/329 [00:10<00:00, 32.02it/s]\n",
      "[valid epoch 44] loss: 0.939, acc: 0.715: 100%|██████████| 313/313 [00:03<00:00, 94.23it/s] \n",
      "[train epoch 45] loss: 0.637, acc: 0.778: 100%|██████████| 329/329 [00:10<00:00, 32.07it/s]\n",
      "[valid epoch 45] loss: 0.950, acc: 0.710: 100%|██████████| 313/313 [00:03<00:00, 94.17it/s] \n",
      "[train epoch 46] loss: 0.636, acc: 0.777: 100%|██████████| 329/329 [00:10<00:00, 32.02it/s]\n",
      "[valid epoch 46] loss: 0.691, acc: 0.769: 100%|██████████| 313/313 [00:03<00:00, 94.02it/s] \n",
      "[train epoch 47] loss: 0.623, acc: 0.787: 100%|██████████| 329/329 [00:10<00:00, 32.01it/s]\n",
      "[valid epoch 47] loss: 0.954, acc: 0.693: 100%|██████████| 313/313 [00:03<00:00, 93.47it/s] \n",
      "[train epoch 48] loss: 0.619, acc: 0.782: 100%|██████████| 329/329 [00:10<00:00, 32.06it/s]\n",
      "[valid epoch 48] loss: 1.036, acc: 0.694: 100%|██████████| 313/313 [00:03<00:00, 94.26it/s] \n",
      "[train epoch 49] loss: 0.638, acc: 0.781: 100%|██████████| 329/329 [00:10<00:00, 32.06it/s]\n",
      "[valid epoch 49] loss: 0.775, acc: 0.742: 100%|██████████| 313/313 [00:03<00:00, 93.19it/s] \n",
      "[train epoch 50] loss: 0.628, acc: 0.784: 100%|██████████| 329/329 [00:11<00:00, 28.80it/s]\n",
      "[valid epoch 50] loss: 0.797, acc: 0.746: 100%|██████████| 313/313 [00:03<00:00, 93.72it/s] \n",
      "[train epoch 51] loss: 0.608, acc: 0.789: 100%|██████████| 329/329 [00:10<00:00, 32.05it/s]\n",
      "[valid epoch 51] loss: 1.307, acc: 0.622: 100%|██████████| 313/313 [00:03<00:00, 93.92it/s] \n",
      "[train epoch 52] loss: 0.608, acc: 0.790: 100%|██████████| 329/329 [00:10<00:00, 32.01it/s]\n",
      "[valid epoch 52] loss: 0.839, acc: 0.725: 100%|██████████| 313/313 [00:03<00:00, 93.60it/s] \n",
      "[train epoch 53] loss: 0.605, acc: 0.794: 100%|██████████| 329/329 [00:10<00:00, 31.94it/s]\n",
      "[valid epoch 53] loss: 0.815, acc: 0.735: 100%|██████████| 313/313 [00:03<00:00, 93.63it/s] \n",
      "[train epoch 54] loss: 0.604, acc: 0.793: 100%|██████████| 329/329 [00:10<00:00, 31.99it/s]\n",
      "[valid epoch 54] loss: 0.913, acc: 0.719: 100%|██████████| 313/313 [00:03<00:00, 93.64it/s] \n",
      "[train epoch 55] loss: 0.603, acc: 0.790: 100%|██████████| 329/329 [00:10<00:00, 31.96it/s]\n",
      "[valid epoch 55] loss: 0.770, acc: 0.750: 100%|██████████| 313/313 [00:03<00:00, 94.09it/s] \n",
      "[train epoch 56] loss: 0.579, acc: 0.802: 100%|██████████| 329/329 [00:10<00:00, 32.01it/s]\n",
      "[valid epoch 56] loss: 1.357, acc: 0.629: 100%|██████████| 313/313 [00:03<00:00, 93.76it/s] \n",
      "[train epoch 57] loss: 0.597, acc: 0.798: 100%|██████████| 329/329 [00:10<00:00, 31.96it/s]\n",
      "[valid epoch 57] loss: 0.729, acc: 0.750: 100%|██████████| 313/313 [00:03<00:00, 93.11it/s] \n",
      "[train epoch 58] loss: 0.597, acc: 0.793: 100%|██████████| 329/329 [00:10<00:00, 31.94it/s]\n",
      "[valid epoch 58] loss: 1.043, acc: 0.689: 100%|██████████| 313/313 [00:03<00:00, 93.39it/s] \n",
      "[train epoch 59] loss: 0.577, acc: 0.798: 100%|██████████| 329/329 [00:10<00:00, 31.95it/s]\n",
      "[valid epoch 59] loss: 0.790, acc: 0.745: 100%|██████████| 313/313 [00:03<00:00, 84.45it/s] \n",
      "[train epoch 60] loss: 0.572, acc: 0.803: 100%|██████████| 329/329 [00:10<00:00, 31.94it/s]\n",
      "[valid epoch 60] loss: 0.890, acc: 0.719: 100%|██████████| 313/313 [00:03<00:00, 93.88it/s] \n",
      "[train epoch 61] loss: 0.567, acc: 0.802: 100%|██████████| 329/329 [00:10<00:00, 31.99it/s]\n",
      "[valid epoch 61] loss: 0.898, acc: 0.716: 100%|██████████| 313/313 [00:03<00:00, 93.07it/s] \n",
      "[train epoch 62] loss: 0.586, acc: 0.799: 100%|██████████| 329/329 [00:10<00:00, 31.91it/s]\n",
      "[valid epoch 62] loss: 0.746, acc: 0.758: 100%|██████████| 313/313 [00:03<00:00, 92.67it/s] \n",
      "[train epoch 63] loss: 0.571, acc: 0.802: 100%|██████████| 329/329 [00:10<00:00, 31.96it/s]\n",
      "[valid epoch 63] loss: 0.923, acc: 0.729: 100%|██████████| 313/313 [00:03<00:00, 93.58it/s] \n",
      "[train epoch 64] loss: 0.562, acc: 0.809: 100%|██████████| 329/329 [00:10<00:00, 31.99it/s]\n",
      "[valid epoch 64] loss: 0.889, acc: 0.725: 100%|██████████| 313/313 [00:03<00:00, 93.23it/s] \n",
      "[train epoch 65] loss: 0.550, acc: 0.811: 100%|██████████| 329/329 [00:10<00:00, 31.92it/s]\n",
      "[valid epoch 65] loss: 0.834, acc: 0.738: 100%|██████████| 313/313 [00:03<00:00, 93.44it/s] \n",
      "[train epoch 66] loss: 0.555, acc: 0.805: 100%|██████████| 329/329 [00:10<00:00, 31.91it/s]\n",
      "[valid epoch 66] loss: 0.713, acc: 0.763: 100%|██████████| 313/313 [00:03<00:00, 93.58it/s] \n",
      "[train epoch 67] loss: 0.538, acc: 0.815: 100%|██████████| 329/329 [00:10<00:00, 32.01it/s]\n",
      "[valid epoch 67] loss: 0.919, acc: 0.720: 100%|██████████| 313/313 [00:03<00:00, 93.11it/s] \n",
      "[train epoch 68] loss: 0.542, acc: 0.812: 100%|██████████| 329/329 [00:10<00:00, 31.91it/s]\n",
      "[valid epoch 68] loss: 1.131, acc: 0.674: 100%|██████████| 313/313 [00:03<00:00, 92.83it/s] \n",
      "[train epoch 69] loss: 0.539, acc: 0.814: 100%|██████████| 329/329 [00:10<00:00, 31.92it/s]\n",
      "[valid epoch 69] loss: 0.774, acc: 0.753: 100%|██████████| 313/313 [00:03<00:00, 92.90it/s] \n",
      "[train epoch 70] loss: 0.529, acc: 0.819: 100%|██████████| 329/329 [00:10<00:00, 31.89it/s]\n",
      "[valid epoch 70] loss: 1.053, acc: 0.700: 100%|██████████| 313/313 [00:03<00:00, 92.84it/s] \n",
      "[train epoch 71] loss: 0.565, acc: 0.805: 100%|██████████| 329/329 [00:10<00:00, 31.91it/s]\n",
      "[valid epoch 71] loss: 0.597, acc: 0.792: 100%|██████████| 313/313 [00:03<00:00, 82.91it/s] \n",
      "[train epoch 72] loss: 0.523, acc: 0.822: 100%|██████████| 329/329 [00:10<00:00, 31.91it/s]\n",
      "[valid epoch 72] loss: 0.900, acc: 0.730: 100%|██████████| 313/313 [00:03<00:00, 92.67it/s] \n",
      "[train epoch 73] loss: 0.547, acc: 0.808: 100%|██████████| 329/329 [00:10<00:00, 31.89it/s]\n",
      "[valid epoch 73] loss: 0.776, acc: 0.755: 100%|██████████| 313/313 [00:03<00:00, 93.54it/s] \n",
      "[train epoch 74] loss: 0.507, acc: 0.826: 100%|██████████| 329/329 [00:10<00:00, 31.89it/s]\n",
      "[valid epoch 74] loss: 0.680, acc: 0.775: 100%|██████████| 313/313 [00:03<00:00, 92.87it/s] \n",
      "[train epoch 75] loss: 0.522, acc: 0.815: 100%|██████████| 329/329 [00:10<00:00, 31.84it/s]\n",
      "[valid epoch 75] loss: 1.018, acc: 0.707: 100%|██████████| 313/313 [00:03<00:00, 92.95it/s] \n",
      "[train epoch 76] loss: 0.509, acc: 0.826: 100%|██████████| 329/329 [00:10<00:00, 31.90it/s]\n",
      "[valid epoch 76] loss: 0.687, acc: 0.778: 100%|██████████| 313/313 [00:03<00:00, 93.04it/s] \n",
      "[train epoch 77] loss: 0.498, acc: 0.828: 100%|██████████| 329/329 [00:10<00:00, 31.88it/s]\n",
      "[valid epoch 77] loss: 0.784, acc: 0.754: 100%|██████████| 313/313 [00:03<00:00, 92.75it/s] \n",
      "[train epoch 78] loss: 0.498, acc: 0.828: 100%|██████████| 329/329 [00:10<00:00, 31.84it/s]\n",
      "[valid epoch 78] loss: 0.852, acc: 0.737: 100%|██████████| 313/313 [00:03<00:00, 92.49it/s] \n",
      "[train epoch 79] loss: 0.498, acc: 0.828: 100%|██████████| 329/329 [00:10<00:00, 31.90it/s]\n",
      "[valid epoch 79] loss: 0.657, acc: 0.784: 100%|██████████| 313/313 [00:03<00:00, 93.14it/s] \n",
      "[train epoch 80] loss: 0.500, acc: 0.831: 100%|██████████| 329/329 [00:10<00:00, 31.87it/s]\n",
      "[valid epoch 80] loss: 0.933, acc: 0.730: 100%|██████████| 313/313 [00:03<00:00, 92.72it/s] \n",
      "[train epoch 81] loss: 0.471, acc: 0.836: 100%|██████████| 329/329 [00:10<00:00, 31.82it/s]\n",
      "[valid epoch 81] loss: 0.807, acc: 0.741: 100%|██████████| 313/313 [00:03<00:00, 92.68it/s] \n",
      "[train epoch 82] loss: 0.486, acc: 0.832: 100%|██████████| 329/329 [00:10<00:00, 31.84it/s]\n",
      "[valid epoch 82] loss: 0.695, acc: 0.778: 100%|██████████| 313/313 [00:03<00:00, 92.98it/s] \n",
      "[train epoch 83] loss: 0.469, acc: 0.838: 100%|██████████| 329/329 [00:10<00:00, 31.87it/s]\n",
      "[valid epoch 83] loss: 0.776, acc: 0.758: 100%|██████████| 313/313 [00:03<00:00, 92.35it/s] \n",
      "[train epoch 84] loss: 0.476, acc: 0.840: 100%|██████████| 329/329 [00:10<00:00, 31.84it/s]\n",
      "[valid epoch 84] loss: 0.911, acc: 0.711: 100%|██████████| 313/313 [00:03<00:00, 81.16it/s] \n",
      "[train epoch 85] loss: 0.469, acc: 0.838: 100%|██████████| 329/329 [00:10<00:00, 31.88it/s]\n",
      "[valid epoch 85] loss: 0.711, acc: 0.765: 100%|██████████| 313/313 [00:03<00:00, 92.36it/s] \n",
      "[train epoch 86] loss: 0.454, acc: 0.844: 100%|██████████| 329/329 [00:10<00:00, 31.84it/s]\n",
      "[valid epoch 86] loss: 0.912, acc: 0.730: 100%|██████████| 313/313 [00:03<00:00, 92.70it/s] \n",
      "[train epoch 87] loss: 0.457, acc: 0.843: 100%|██████████| 329/329 [00:10<00:00, 31.84it/s]\n",
      "[valid epoch 87] loss: 0.896, acc: 0.724: 100%|██████████| 313/313 [00:03<00:00, 92.58it/s] \n",
      "[train epoch 88] loss: 0.484, acc: 0.832: 100%|██████████| 329/329 [00:10<00:00, 31.85it/s]\n",
      "[valid epoch 88] loss: 1.431, acc: 0.643: 100%|██████████| 313/313 [00:03<00:00, 92.74it/s] \n",
      "[train epoch 89] loss: 0.448, acc: 0.845: 100%|██████████| 329/329 [00:10<00:00, 31.81it/s]\n",
      "[valid epoch 89] loss: 0.703, acc: 0.780: 100%|██████████| 313/313 [00:03<00:00, 91.83it/s] \n",
      "[train epoch 90] loss: 0.433, acc: 0.849: 100%|██████████| 329/329 [00:10<00:00, 31.82it/s]\n",
      "[valid epoch 90] loss: 0.664, acc: 0.788: 100%|██████████| 313/313 [00:03<00:00, 92.39it/s] \n",
      "[train epoch 91] loss: 0.440, acc: 0.850: 100%|██████████| 329/329 [00:10<00:00, 31.77it/s]\n",
      "[valid epoch 91] loss: 0.798, acc: 0.748: 100%|██████████| 313/313 [00:03<00:00, 92.88it/s] \n",
      "[train epoch 92] loss: 0.441, acc: 0.850: 100%|██████████| 329/329 [00:10<00:00, 31.83it/s]\n",
      "[valid epoch 92] loss: 0.639, acc: 0.792: 100%|██████████| 313/313 [00:03<00:00, 92.69it/s] \n",
      "[train epoch 93] loss: 0.432, acc: 0.850: 100%|██████████| 329/329 [00:10<00:00, 31.79it/s]\n",
      "[valid epoch 93] loss: 0.661, acc: 0.785: 100%|██████████| 313/313 [00:03<00:00, 92.34it/s] \n",
      "[train epoch 94] loss: 0.410, acc: 0.858: 100%|██████████| 329/329 [00:10<00:00, 31.77it/s]\n",
      "[valid epoch 94] loss: 0.758, acc: 0.768: 100%|██████████| 313/313 [00:03<00:00, 92.85it/s] \n",
      "[train epoch 95] loss: 0.417, acc: 0.857: 100%|██████████| 329/329 [00:10<00:00, 31.83it/s]\n",
      "[valid epoch 95] loss: 0.744, acc: 0.766: 100%|██████████| 313/313 [00:03<00:00, 92.33it/s] \n",
      "[train epoch 96] loss: 0.408, acc: 0.858: 100%|██████████| 329/329 [00:10<00:00, 31.84it/s]\n",
      "[valid epoch 96] loss: 0.669, acc: 0.791: 100%|██████████| 313/313 [00:03<00:00, 92.28it/s] \n",
      "[train epoch 97] loss: 0.408, acc: 0.858: 100%|██████████| 329/329 [00:10<00:00, 31.78it/s]\n",
      "[valid epoch 97] loss: 0.702, acc: 0.782: 100%|██████████| 313/313 [00:03<00:00, 92.52it/s] \n",
      "[train epoch 98] loss: 0.395, acc: 0.865: 100%|██████████| 329/329 [00:10<00:00, 31.80it/s]\n",
      "[valid epoch 98] loss: 0.667, acc: 0.787: 100%|██████████| 313/313 [00:03<00:00, 92.35it/s] \n",
      "[train epoch 99] loss: 0.395, acc: 0.864: 100%|██████████| 329/329 [00:10<00:00, 31.80it/s]\n",
      "[valid epoch 99] loss: 0.722, acc: 0.781: 100%|██████████| 313/313 [00:03<00:00, 79.62it/s] \n",
      "[train epoch 100] loss: 0.395, acc: 0.863: 100%|██████████| 329/329 [00:10<00:00, 31.81it/s]\n",
      "[valid epoch 100] loss: 0.647, acc: 0.798: 100%|██████████| 313/313 [00:03<00:00, 92.15it/s] \n",
      "[train epoch 101] loss: 0.390, acc: 0.866: 100%|██████████| 329/329 [00:10<00:00, 31.74it/s]\n",
      "[valid epoch 101] loss: 0.899, acc: 0.739: 100%|██████████| 313/313 [00:03<00:00, 91.82it/s] \n",
      "[train epoch 102] loss: 0.381, acc: 0.870: 100%|██████████| 329/329 [00:10<00:00, 31.73it/s]\n",
      "[valid epoch 102] loss: 0.694, acc: 0.781: 100%|██████████| 313/313 [00:03<00:00, 91.34it/s] \n",
      "[train epoch 103] loss: 0.394, acc: 0.866: 100%|██████████| 329/329 [00:10<00:00, 31.79it/s]\n",
      "[valid epoch 103] loss: 0.728, acc: 0.776: 100%|██████████| 313/313 [00:03<00:00, 92.08it/s] \n",
      "[train epoch 104] loss: 0.383, acc: 0.866: 100%|██████████| 329/329 [00:10<00:00, 31.79it/s]\n",
      "[valid epoch 104] loss: 0.646, acc: 0.802: 100%|██████████| 313/313 [00:03<00:00, 92.04it/s] \n",
      "[train epoch 105] loss: 0.371, acc: 0.871: 100%|██████████| 329/329 [00:10<00:00, 31.76it/s]\n",
      "[valid epoch 105] loss: 0.834, acc: 0.763: 100%|██████████| 313/313 [00:03<00:00, 92.50it/s] \n",
      "[train epoch 106] loss: 0.384, acc: 0.866: 100%|██████████| 329/329 [00:10<00:00, 31.76it/s]\n",
      "[valid epoch 106] loss: 0.736, acc: 0.771: 100%|██████████| 313/313 [00:03<00:00, 91.97it/s] \n",
      "[train epoch 107] loss: 0.369, acc: 0.872: 100%|██████████| 329/329 [00:10<00:00, 31.77it/s]\n",
      "[valid epoch 107] loss: 0.692, acc: 0.792: 100%|██████████| 313/313 [00:03<00:00, 91.52it/s] \n",
      "[train epoch 108] loss: 0.328, acc: 0.886: 100%|██████████| 329/329 [00:10<00:00, 31.76it/s]\n",
      "[valid epoch 108] loss: 0.717, acc: 0.781: 100%|██████████| 313/313 [00:03<00:00, 92.11it/s] \n",
      "[train epoch 109] loss: 0.362, acc: 0.873: 100%|██████████| 329/329 [00:10<00:00, 31.72it/s]\n",
      "[valid epoch 109] loss: 0.761, acc: 0.778: 100%|██████████| 313/313 [00:03<00:00, 91.48it/s] \n",
      "[train epoch 110] loss: 0.327, acc: 0.888: 100%|██████████| 329/329 [00:10<00:00, 31.77it/s]\n",
      "[valid epoch 110] loss: 0.747, acc: 0.789: 100%|██████████| 313/313 [00:03<00:00, 92.21it/s] \n",
      "[train epoch 111] loss: 0.321, acc: 0.891: 100%|██████████| 329/329 [00:10<00:00, 31.73it/s]\n",
      "[valid epoch 111] loss: 0.633, acc: 0.807: 100%|██████████| 313/313 [00:03<00:00, 91.20it/s] \n",
      "[train epoch 112] loss: 0.308, acc: 0.891: 100%|██████████| 329/329 [00:10<00:00, 31.75it/s]\n",
      "[valid epoch 112] loss: 0.601, acc: 0.816: 100%|██████████| 313/313 [00:03<00:00, 92.10it/s] \n",
      "[train epoch 113] loss: 0.303, acc: 0.896: 100%|██████████| 329/329 [00:10<00:00, 31.78it/s]\n",
      "[valid epoch 113] loss: 0.625, acc: 0.808: 100%|██████████| 313/313 [00:03<00:00, 91.57it/s] \n",
      "[train epoch 114] loss: 0.302, acc: 0.898: 100%|██████████| 329/329 [00:10<00:00, 31.63it/s]\n",
      "[valid epoch 114] loss: 0.744, acc: 0.778: 100%|██████████| 313/313 [00:03<00:00, 91.50it/s] \n",
      "[train epoch 115] loss: 0.312, acc: 0.894: 100%|██████████| 329/329 [00:10<00:00, 31.71it/s]\n",
      "[valid epoch 115] loss: 0.679, acc: 0.790: 100%|██████████| 313/313 [00:03<00:00, 92.68it/s] \n",
      "[train epoch 116] loss: 0.284, acc: 0.905: 100%|██████████| 329/329 [00:10<00:00, 31.70it/s]\n",
      "[valid epoch 116] loss: 0.596, acc: 0.817: 100%|██████████| 313/313 [00:03<00:00, 91.26it/s] \n",
      "[train epoch 117] loss: 0.289, acc: 0.901: 100%|██████████| 329/329 [00:11<00:00, 27.86it/s]\n",
      "[valid epoch 117] loss: 0.907, acc: 0.756: 100%|██████████| 313/313 [00:05<00:00, 56.12it/s] \n",
      "[train epoch 118] loss: 0.312, acc: 0.892: 100%|██████████| 329/329 [00:10<00:00, 31.74it/s]\n",
      "[valid epoch 118] loss: 0.719, acc: 0.784: 100%|██████████| 313/313 [00:03<00:00, 92.20it/s] \n",
      "[train epoch 119] loss: 0.290, acc: 0.902: 100%|██████████| 329/329 [00:10<00:00, 31.76it/s]\n",
      "[valid epoch 119] loss: 0.722, acc: 0.793: 100%|██████████| 313/313 [00:03<00:00, 92.12it/s] \n",
      "[train epoch 120] loss: 0.299, acc: 0.900: 100%|██████████| 329/329 [00:10<00:00, 31.74it/s]\n",
      "[valid epoch 120] loss: 0.600, acc: 0.814: 100%|██████████| 313/313 [00:03<00:00, 92.18it/s] \n",
      "[train epoch 121] loss: 0.293, acc: 0.902: 100%|██████████| 329/329 [00:10<00:00, 31.73it/s]\n",
      "[valid epoch 121] loss: 0.626, acc: 0.812: 100%|██████████| 313/313 [00:03<00:00, 91.19it/s] \n",
      "[train epoch 122] loss: 0.272, acc: 0.908: 100%|██████████| 329/329 [00:10<00:00, 31.72it/s]\n",
      "[valid epoch 122] loss: 0.722, acc: 0.800: 100%|██████████| 313/313 [00:03<00:00, 91.15it/s] \n",
      "[train epoch 123] loss: 0.249, acc: 0.916: 100%|██████████| 329/329 [00:10<00:00, 31.65it/s]\n",
      "[valid epoch 123] loss: 0.620, acc: 0.822: 100%|██████████| 313/313 [00:03<00:00, 91.77it/s] \n",
      "[train epoch 124] loss: 0.265, acc: 0.912: 100%|██████████| 329/329 [00:10<00:00, 31.74it/s]\n",
      "[valid epoch 124] loss: 0.705, acc: 0.802: 100%|██████████| 313/313 [00:03<00:00, 91.70it/s] \n",
      "[train epoch 125] loss: 0.232, acc: 0.921: 100%|██████████| 329/329 [00:10<00:00, 31.63it/s]\n",
      "[valid epoch 125] loss: 0.753, acc: 0.793: 100%|██████████| 313/313 [00:03<00:00, 91.63it/s] \n",
      "[train epoch 126] loss: 0.241, acc: 0.919: 100%|██████████| 329/329 [00:10<00:00, 31.68it/s]\n",
      "[valid epoch 126] loss: 0.699, acc: 0.811: 100%|██████████| 313/313 [00:03<00:00, 91.52it/s] \n",
      "[train epoch 127] loss: 0.238, acc: 0.918: 100%|██████████| 329/329 [00:10<00:00, 31.71it/s]\n",
      "[valid epoch 127] loss: 0.647, acc: 0.810: 100%|██████████| 313/313 [00:03<00:00, 90.75it/s] \n",
      "[train epoch 128] loss: 0.199, acc: 0.932: 100%|██████████| 329/329 [00:10<00:00, 31.62it/s]\n",
      "[valid epoch 128] loss: 0.697, acc: 0.806: 100%|██████████| 313/313 [00:03<00:00, 91.09it/s] \n",
      "[train epoch 129] loss: 0.205, acc: 0.933: 100%|██████████| 329/329 [00:10<00:00, 31.60it/s]\n",
      "[valid epoch 129] loss: 0.602, acc: 0.827: 100%|██████████| 313/313 [00:03<00:00, 90.75it/s] \n",
      "[train epoch 130] loss: 0.214, acc: 0.927: 100%|██████████| 329/329 [00:10<00:00, 31.59it/s]\n",
      "[valid epoch 130] loss: 0.600, acc: 0.825: 100%|██████████| 313/313 [00:03<00:00, 91.22it/s] \n",
      "[train epoch 131] loss: 0.211, acc: 0.926: 100%|██████████| 329/329 [00:10<00:00, 31.59it/s]\n",
      "[valid epoch 131] loss: 0.625, acc: 0.819: 100%|██████████| 313/313 [00:03<00:00, 90.80it/s] \n",
      "[train epoch 132] loss: 0.192, acc: 0.935: 100%|██████████| 329/329 [00:10<00:00, 31.63it/s]\n",
      "[valid epoch 132] loss: 0.616, acc: 0.826: 100%|██████████| 313/313 [00:03<00:00, 91.64it/s] \n",
      "[train epoch 133] loss: 0.187, acc: 0.933: 100%|██████████| 329/329 [00:10<00:00, 31.67it/s]\n",
      "[valid epoch 133] loss: 0.625, acc: 0.822: 100%|██████████| 313/313 [00:03<00:00, 90.78it/s] \n",
      "[train epoch 134] loss: 0.173, acc: 0.945: 100%|██████████| 329/329 [00:10<00:00, 31.59it/s]\n",
      "[valid epoch 134] loss: 0.718, acc: 0.813: 100%|██████████| 313/313 [00:03<00:00, 91.07it/s] \n",
      "[train epoch 135] loss: 0.206, acc: 0.927: 100%|██████████| 329/329 [00:10<00:00, 31.58it/s]\n",
      "[valid epoch 135] loss: 0.647, acc: 0.820: 100%|██████████| 313/313 [00:03<00:00, 90.92it/s] \n",
      "[train epoch 136] loss: 0.175, acc: 0.940: 100%|██████████| 329/329 [00:10<00:00, 31.66it/s]\n",
      "[valid epoch 136] loss: 0.675, acc: 0.821: 100%|██████████| 313/313 [00:03<00:00, 90.60it/s] \n",
      "[train epoch 137] loss: 0.175, acc: 0.938: 100%|██████████| 329/329 [00:10<00:00, 31.61it/s]\n",
      "[valid epoch 137] loss: 0.646, acc: 0.815: 100%|██████████| 313/313 [00:04<00:00, 75.30it/s] \n",
      "[train epoch 138] loss: 0.153, acc: 0.948: 100%|██████████| 329/329 [00:10<00:00, 31.62it/s]\n",
      "[valid epoch 138] loss: 0.708, acc: 0.816: 100%|██████████| 313/313 [00:03<00:00, 90.53it/s] \n",
      "[train epoch 139] loss: 0.154, acc: 0.946: 100%|██████████| 329/329 [00:10<00:00, 31.66it/s]\n",
      "[valid epoch 139] loss: 0.638, acc: 0.817: 100%|██████████| 313/313 [00:03<00:00, 91.12it/s] \n",
      "[train epoch 140] loss: 0.144, acc: 0.953: 100%|██████████| 329/329 [00:10<00:00, 31.59it/s]\n",
      "[valid epoch 140] loss: 0.573, acc: 0.840: 100%|██████████| 313/313 [00:03<00:00, 90.95it/s] \n",
      "[train epoch 141] loss: 0.140, acc: 0.953: 100%|██████████| 329/329 [00:10<00:00, 31.65it/s]\n",
      "[valid epoch 141] loss: 0.625, acc: 0.827: 100%|██████████| 313/313 [00:03<00:00, 90.72it/s] \n",
      "[train epoch 142] loss: 0.126, acc: 0.957: 100%|██████████| 329/329 [00:10<00:00, 31.64it/s]\n",
      "[valid epoch 142] loss: 0.663, acc: 0.823: 100%|██████████| 313/313 [00:03<00:00, 91.40it/s] \n",
      "[train epoch 143] loss: 0.133, acc: 0.955: 100%|██████████| 329/329 [00:10<00:00, 31.57it/s]\n",
      "[valid epoch 143] loss: 0.791, acc: 0.795: 100%|██████████| 313/313 [00:03<00:00, 90.61it/s] \n",
      "[train epoch 144] loss: 0.114, acc: 0.959: 100%|██████████| 329/329 [00:10<00:00, 31.51it/s]\n",
      "[valid epoch 144] loss: 0.682, acc: 0.820: 100%|██████████| 313/313 [00:03<00:00, 90.51it/s] \n",
      "[train epoch 145] loss: 0.119, acc: 0.960: 100%|██████████| 329/329 [00:10<00:00, 31.61it/s]\n",
      "[valid epoch 145] loss: 0.697, acc: 0.829: 100%|██████████| 313/313 [00:03<00:00, 90.56it/s] \n",
      "[train epoch 146] loss: 0.119, acc: 0.961: 100%|██████████| 329/329 [00:10<00:00, 31.59it/s]\n",
      "[valid epoch 146] loss: 0.752, acc: 0.810: 100%|██████████| 313/313 [00:03<00:00, 90.76it/s] \n",
      "[train epoch 147] loss: 0.098, acc: 0.966: 100%|██████████| 329/329 [00:10<00:00, 31.55it/s]\n",
      "[valid epoch 147] loss: 0.598, acc: 0.842: 100%|██████████| 313/313 [00:03<00:00, 90.71it/s] \n",
      "[train epoch 148] loss: 0.091, acc: 0.971: 100%|██████████| 329/329 [00:10<00:00, 31.61it/s]\n",
      "[valid epoch 148] loss: 0.651, acc: 0.838: 100%|██████████| 313/313 [00:03<00:00, 90.69it/s] \n",
      "[train epoch 149] loss: 0.106, acc: 0.965: 100%|██████████| 329/329 [00:10<00:00, 31.60it/s]\n",
      "[valid epoch 149] loss: 0.689, acc: 0.823: 100%|██████████| 313/313 [00:03<00:00, 90.64it/s] \n",
      "[train epoch 150] loss: 0.095, acc: 0.968: 100%|██████████| 329/329 [00:10<00:00, 31.52it/s]\n",
      "[valid epoch 150] loss: 0.632, acc: 0.837: 100%|██████████| 313/313 [00:03<00:00, 91.00it/s] \n",
      "[train epoch 151] loss: 0.083, acc: 0.973: 100%|██████████| 329/329 [00:10<00:00, 31.54it/s]\n",
      "[valid epoch 151] loss: 0.633, acc: 0.839: 100%|██████████| 313/313 [00:03<00:00, 90.50it/s] \n",
      "[train epoch 152] loss: 0.075, acc: 0.976: 100%|██████████| 329/329 [00:10<00:00, 31.60it/s]\n",
      "[valid epoch 152] loss: 0.704, acc: 0.828: 100%|██████████| 313/313 [00:03<00:00, 89.75it/s] \n",
      "[train epoch 153] loss: 0.073, acc: 0.976: 100%|██████████| 329/329 [00:10<00:00, 31.59it/s]\n",
      "[valid epoch 153] loss: 0.611, acc: 0.846: 100%|██████████| 313/313 [00:03<00:00, 89.53it/s] \n",
      "[train epoch 154] loss: 0.070, acc: 0.978: 100%|██████████| 329/329 [00:10<00:00, 31.59it/s]\n",
      "[valid epoch 154] loss: 0.669, acc: 0.832: 100%|██████████| 313/313 [00:03<00:00, 91.00it/s] \n",
      "[train epoch 155] loss: 0.080, acc: 0.974: 100%|██████████| 329/329 [00:10<00:00, 31.57it/s]\n",
      "[valid epoch 155] loss: 0.610, acc: 0.849: 100%|██████████| 313/313 [00:03<00:00, 90.86it/s] \n",
      "[train epoch 156] loss: 0.045, acc: 0.986: 100%|██████████| 329/329 [00:10<00:00, 31.49it/s]\n",
      "[valid epoch 156] loss: 0.597, acc: 0.852: 100%|██████████| 313/313 [00:03<00:00, 90.48it/s] \n",
      "[train epoch 157] loss: 0.050, acc: 0.985: 100%|██████████| 329/329 [00:10<00:00, 31.52it/s]\n",
      "[valid epoch 157] loss: 0.612, acc: 0.856: 100%|██████████| 313/313 [00:03<00:00, 90.55it/s] \n",
      "[train epoch 158] loss: 0.043, acc: 0.987: 100%|██████████| 329/329 [00:10<00:00, 31.54it/s]\n",
      "[valid epoch 158] loss: 0.624, acc: 0.847: 100%|██████████| 313/313 [00:03<00:00, 90.20it/s] \n",
      "[train epoch 159] loss: 0.064, acc: 0.979: 100%|██████████| 329/329 [00:10<00:00, 31.60it/s]\n",
      "[valid epoch 159] loss: 0.669, acc: 0.842: 100%|██████████| 313/313 [00:03<00:00, 90.02it/s] \n",
      "[train epoch 160] loss: 0.074, acc: 0.976: 100%|██████████| 329/329 [00:10<00:00, 31.54it/s]\n",
      "[valid epoch 160] loss: 0.592, acc: 0.857: 100%|██████████| 313/313 [00:04<00:00, 73.09it/s] \n",
      "[train epoch 161] loss: 0.038, acc: 0.989: 100%|██████████| 329/329 [00:10<00:00, 31.49it/s]\n",
      "[valid epoch 161] loss: 0.664, acc: 0.842: 100%|██████████| 313/313 [00:03<00:00, 90.54it/s] \n",
      "[train epoch 162] loss: 0.041, acc: 0.989: 100%|██████████| 329/329 [00:10<00:00, 31.59it/s]\n",
      "[valid epoch 162] loss: 0.613, acc: 0.855: 100%|██████████| 313/313 [00:03<00:00, 89.65it/s] \n",
      "[train epoch 163] loss: 0.049, acc: 0.986: 100%|██████████| 329/329 [00:10<00:00, 31.56it/s]\n",
      "[valid epoch 163] loss: 0.611, acc: 0.852: 100%|██████████| 313/313 [00:03<00:00, 89.87it/s] \n",
      "[train epoch 164] loss: 0.029, acc: 0.992: 100%|██████████| 329/329 [00:10<00:00, 31.55it/s]\n",
      "[valid epoch 164] loss: 0.640, acc: 0.849: 100%|██████████| 313/313 [00:03<00:00, 90.77it/s] \n",
      "[train epoch 165] loss: 0.019, acc: 0.995: 100%|██████████| 329/329 [00:10<00:00, 31.50it/s]\n",
      "[valid epoch 165] loss: 0.655, acc: 0.851: 100%|██████████| 313/313 [00:03<00:00, 89.68it/s] \n",
      "[train epoch 166] loss: 0.019, acc: 0.994: 100%|██████████| 329/329 [00:10<00:00, 31.51it/s]\n",
      "[valid epoch 166] loss: 0.567, acc: 0.866: 100%|██████████| 313/313 [00:03<00:00, 90.54it/s] \n",
      "[train epoch 167] loss: 0.018, acc: 0.995: 100%|██████████| 329/329 [00:10<00:00, 31.53it/s]\n",
      "[valid epoch 167] loss: 0.558, acc: 0.867: 100%|██████████| 313/313 [00:03<00:00, 90.83it/s] \n",
      "[train epoch 168] loss: 0.015, acc: 0.996: 100%|██████████| 329/329 [00:10<00:00, 31.45it/s]\n",
      "[valid epoch 168] loss: 0.573, acc: 0.867: 100%|██████████| 313/313 [00:03<00:00, 90.14it/s] \n",
      "[train epoch 169] loss: 0.010, acc: 0.998: 100%|██████████| 329/329 [00:10<00:00, 31.57it/s]\n",
      "[valid epoch 169] loss: 0.569, acc: 0.867: 100%|██████████| 313/313 [00:03<00:00, 90.23it/s] \n",
      "[train epoch 170] loss: 0.007, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.49it/s]\n",
      "[valid epoch 170] loss: 0.543, acc: 0.868: 100%|██████████| 313/313 [00:03<00:00, 89.36it/s] \n",
      "[train epoch 171] loss: 0.009, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.54it/s]\n",
      "[valid epoch 171] loss: 0.557, acc: 0.869: 100%|██████████| 313/313 [00:03<00:00, 90.04it/s] \n",
      "[train epoch 172] loss: 0.029, acc: 0.991: 100%|██████████| 329/329 [00:10<00:00, 31.54it/s]\n",
      "[valid epoch 172] loss: 0.574, acc: 0.863: 100%|██████████| 313/313 [00:03<00:00, 89.15it/s] \n",
      "[train epoch 173] loss: 0.010, acc: 0.998: 100%|██████████| 329/329 [00:10<00:00, 31.50it/s]\n",
      "[valid epoch 173] loss: 0.538, acc: 0.870: 100%|██████████| 313/313 [00:03<00:00, 90.22it/s] \n",
      "[train epoch 174] loss: 0.009, acc: 0.998: 100%|██████████| 329/329 [00:10<00:00, 31.51it/s]\n",
      "[valid epoch 174] loss: 0.528, acc: 0.872: 100%|██████████| 313/313 [00:03<00:00, 89.39it/s] \n",
      "[train epoch 175] loss: 0.007, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.47it/s]\n",
      "[valid epoch 175] loss: 0.527, acc: 0.870: 100%|██████████| 313/313 [00:03<00:00, 89.41it/s] \n",
      "[train epoch 176] loss: 0.007, acc: 0.998: 100%|██████████| 329/329 [00:10<00:00, 31.48it/s]\n",
      "[valid epoch 176] loss: 0.531, acc: 0.870: 100%|██████████| 313/313 [00:03<00:00, 89.52it/s] \n",
      "[train epoch 177] loss: 0.012, acc: 0.998: 100%|██████████| 329/329 [00:10<00:00, 31.48it/s]\n",
      "[valid epoch 177] loss: 0.526, acc: 0.874: 100%|██████████| 313/313 [00:03<00:00, 90.21it/s] \n",
      "[train epoch 178] loss: 0.010, acc: 0.998: 100%|██████████| 329/329 [00:10<00:00, 31.54it/s]\n",
      "[valid epoch 178] loss: 0.551, acc: 0.870: 100%|██████████| 313/313 [00:03<00:00, 89.26it/s] \n",
      "[train epoch 179] loss: 0.006, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.46it/s]\n",
      "[valid epoch 179] loss: 0.541, acc: 0.870: 100%|██████████| 313/313 [00:03<00:00, 89.16it/s] \n",
      "[train epoch 180] loss: 0.005, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.40it/s]\n",
      "[valid epoch 180] loss: 0.532, acc: 0.874: 100%|██████████| 313/313 [00:03<00:00, 89.63it/s] \n",
      "[train epoch 181] loss: 0.004, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.38it/s]\n",
      "[valid epoch 181] loss: 0.532, acc: 0.875: 100%|██████████| 313/313 [00:03<00:00, 89.97it/s] \n",
      "[train epoch 182] loss: 0.006, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.42it/s]\n",
      "[valid epoch 182] loss: 0.531, acc: 0.875: 100%|██████████| 313/313 [00:03<00:00, 89.90it/s] \n",
      "[train epoch 183] loss: 0.005, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.42it/s]\n",
      "[valid epoch 183] loss: 0.517, acc: 0.876: 100%|██████████| 313/313 [00:03<00:00, 89.49it/s] \n",
      "[train epoch 184] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.46it/s]\n",
      "[valid epoch 184] loss: 0.525, acc: 0.874: 100%|██████████| 313/313 [00:03<00:00, 89.26it/s] \n",
      "[train epoch 185] loss: 0.004, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.45it/s]\n",
      "[valid epoch 185] loss: 0.517, acc: 0.875: 100%|██████████| 313/313 [00:03<00:00, 90.15it/s] \n",
      "[train epoch 186] loss: 0.004, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.50it/s]\n",
      "[valid epoch 186] loss: 0.530, acc: 0.877: 100%|██████████| 313/313 [00:03<00:00, 89.39it/s] \n",
      "[train epoch 187] loss: 0.004, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.44it/s]\n",
      "[valid epoch 187] loss: 0.516, acc: 0.878: 100%|██████████| 313/313 [00:03<00:00, 89.25it/s] \n",
      "[train epoch 188] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.48it/s]\n",
      "[valid epoch 188] loss: 0.525, acc: 0.876: 100%|██████████| 313/313 [00:04<00:00, 70.21it/s] \n",
      "[train epoch 189] loss: 0.004, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.45it/s]\n",
      "[valid epoch 189] loss: 0.518, acc: 0.875: 100%|██████████| 313/313 [00:03<00:00, 90.79it/s] \n",
      "[train epoch 190] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.45it/s]\n",
      "[valid epoch 190] loss: 0.517, acc: 0.876: 100%|██████████| 313/313 [00:03<00:00, 89.54it/s] \n",
      "[train epoch 191] loss: 0.004, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.44it/s]\n",
      "[valid epoch 191] loss: 0.519, acc: 0.876: 100%|██████████| 313/313 [00:03<00:00, 89.26it/s] \n",
      "[train epoch 192] loss: 0.006, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.44it/s]\n",
      "[valid epoch 192] loss: 0.516, acc: 0.877: 100%|██████████| 313/313 [00:03<00:00, 89.53it/s] \n",
      "[train epoch 193] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.33it/s]\n",
      "[valid epoch 193] loss: 0.514, acc: 0.876: 100%|██████████| 313/313 [00:03<00:00, 89.43it/s] \n",
      "[train epoch 194] loss: 0.008, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.37it/s]\n",
      "[valid epoch 194] loss: 0.517, acc: 0.878: 100%|██████████| 313/313 [00:03<00:00, 89.47it/s] \n",
      "[train epoch 195] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.43it/s]\n",
      "[valid epoch 195] loss: 0.509, acc: 0.877: 100%|██████████| 313/313 [00:03<00:00, 90.20it/s] \n",
      "[train epoch 196] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.37it/s]\n",
      "[valid epoch 196] loss: 0.515, acc: 0.877: 100%|██████████| 313/313 [00:03<00:00, 89.07it/s] \n",
      "[train epoch 197] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.38it/s]\n",
      "[valid epoch 197] loss: 0.509, acc: 0.877: 100%|██████████| 313/313 [00:03<00:00, 89.34it/s] \n",
      "[train epoch 198] loss: 0.003, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.38it/s]\n",
      "[valid epoch 198] loss: 0.502, acc: 0.880: 100%|██████████| 313/313 [00:03<00:00, 88.66it/s] \n",
      "[train epoch 199] loss: 0.004, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.36it/s]\n",
      "[valid epoch 199] loss: 0.509, acc: 0.878: 100%|██████████| 313/313 [00:03<00:00, 89.03it/s] \n",
      "[train epoch 200] loss: 0.007, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.29it/s]\n",
      "[valid epoch 200] loss: 0.515, acc: 0.877: 100%|██████████| 313/313 [00:03<00:00, 89.11it/s] \n",
      "[train epoch 201] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.38it/s]\n",
      "[valid epoch 201] loss: 0.513, acc: 0.875: 100%|██████████| 313/313 [00:03<00:00, 88.81it/s] \n",
      "[train epoch 202] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.32it/s]\n",
      "[valid epoch 202] loss: 0.506, acc: 0.878: 100%|██████████| 313/313 [00:03<00:00, 89.60it/s] \n",
      "[train epoch 203] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.32it/s]\n",
      "[valid epoch 203] loss: 0.508, acc: 0.878: 100%|██████████| 313/313 [00:03<00:00, 88.85it/s] \n",
      "[train epoch 204] loss: 0.002, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.26it/s]\n",
      "[valid epoch 204] loss: 0.510, acc: 0.877: 100%|██████████| 313/313 [00:03<00:00, 89.44it/s] \n",
      "[train epoch 205] loss: 0.004, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.35it/s]\n",
      "[valid epoch 205] loss: 0.514, acc: 0.877: 100%|██████████| 313/313 [00:03<00:00, 89.56it/s] \n",
      "[train epoch 206] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.33it/s]\n",
      "[valid epoch 206] loss: 0.521, acc: 0.876: 100%|██████████| 313/313 [00:03<00:00, 89.44it/s] \n",
      "[train epoch 207] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.39it/s]\n",
      "[valid epoch 207] loss: 0.509, acc: 0.879: 100%|██████████| 313/313 [00:03<00:00, 88.39it/s] \n",
      "[train epoch 208] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.38it/s]\n",
      "[valid epoch 208] loss: 0.521, acc: 0.875: 100%|██████████| 313/313 [00:03<00:00, 88.86it/s] \n",
      "[train epoch 209] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.39it/s]\n",
      "[valid epoch 209] loss: 0.516, acc: 0.876: 100%|██████████| 313/313 [00:03<00:00, 88.84it/s] \n",
      "[train epoch 210] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.41it/s]\n",
      "[valid epoch 210] loss: 0.507, acc: 0.879: 100%|██████████| 313/313 [00:03<00:00, 89.08it/s] \n",
      "[train epoch 211] loss: 0.002, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.37it/s]\n",
      "[valid epoch 211] loss: 0.507, acc: 0.877: 100%|██████████| 313/313 [00:03<00:00, 88.66it/s] \n",
      "[train epoch 212] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.35it/s]\n",
      "[valid epoch 212] loss: 0.517, acc: 0.878: 100%|██████████| 313/313 [00:03<00:00, 88.41it/s] \n",
      "[train epoch 213] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.34it/s]\n",
      "[valid epoch 213] loss: 0.515, acc: 0.877: 100%|██████████| 313/313 [00:03<00:00, 88.15it/s] \n",
      "[train epoch 214] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.38it/s]\n",
      "[valid epoch 214] loss: 0.500, acc: 0.878: 100%|██████████| 313/313 [00:03<00:00, 88.97it/s] \n",
      "[train epoch 215] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.30it/s]\n",
      "[valid epoch 215] loss: 0.509, acc: 0.878: 100%|██████████| 313/313 [00:03<00:00, 88.47it/s] \n",
      "[train epoch 216] loss: 0.004, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.16it/s]\n",
      "[valid epoch 216] loss: 0.508, acc: 0.878: 100%|██████████| 313/313 [00:03<00:00, 88.66it/s] \n",
      "[train epoch 217] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.23it/s]\n",
      "[valid epoch 217] loss: 0.503, acc: 0.878: 100%|██████████| 313/313 [00:03<00:00, 85.09it/s] \n",
      "[train epoch 218] loss: 0.004, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.11it/s]\n",
      "[valid epoch 218] loss: 0.510, acc: 0.878: 100%|██████████| 313/313 [00:03<00:00, 88.07it/s] \n",
      "[train epoch 219] loss: 0.006, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.24it/s]\n",
      "[valid epoch 219] loss: 0.518, acc: 0.873: 100%|██████████| 313/313 [00:03<00:00, 88.48it/s] \n",
      "[train epoch 220] loss: 0.005, acc: 0.999: 100%|██████████| 329/329 [00:14<00:00, 22.49it/s]\n",
      "[valid epoch 220] loss: 0.527, acc: 0.872: 100%|██████████| 313/313 [00:04<00:00, 64.57it/s] \n",
      "[train epoch 221] loss: 0.008, acc: 0.998: 100%|██████████| 329/329 [00:10<00:00, 31.05it/s]\n",
      "[valid epoch 221] loss: 0.519, acc: 0.872: 100%|██████████| 313/313 [00:03<00:00, 87.99it/s] \n",
      "[train epoch 222] loss: 0.007, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.03it/s]\n",
      "[valid epoch 222] loss: 0.535, acc: 0.872: 100%|██████████| 313/313 [00:03<00:00, 88.36it/s] \n",
      "[train epoch 223] loss: 0.010, acc: 0.998: 100%|██████████| 329/329 [00:10<00:00, 31.13it/s]\n",
      "[valid epoch 223] loss: 0.534, acc: 0.868: 100%|██████████| 313/313 [00:03<00:00, 88.31it/s] \n",
      "[train epoch 224] loss: 0.011, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.12it/s]\n",
      "[valid epoch 224] loss: 0.521, acc: 0.871: 100%|██████████| 313/313 [00:03<00:00, 87.89it/s] \n",
      "[train epoch 225] loss: 0.011, acc: 0.997: 100%|██████████| 329/329 [00:10<00:00, 31.13it/s]\n",
      "[valid epoch 225] loss: 0.527, acc: 0.873: 100%|██████████| 313/313 [00:03<00:00, 88.33it/s] \n",
      "[train epoch 226] loss: 0.005, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.04it/s]\n",
      "[valid epoch 226] loss: 0.525, acc: 0.873: 100%|██████████| 313/313 [00:03<00:00, 88.16it/s] \n",
      "[train epoch 227] loss: 0.003, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.06it/s]\n",
      "[valid epoch 227] loss: 0.524, acc: 0.875: 100%|██████████| 313/313 [00:03<00:00, 88.18it/s] \n",
      "[train epoch 228] loss: 0.006, acc: 0.999: 100%|██████████| 329/329 [00:10<00:00, 31.09it/s]\n",
      "[valid epoch 228] loss: 0.547, acc: 0.869: 100%|██████████| 313/313 [00:03<00:00, 88.11it/s] \n",
      "[train epoch 229] loss: 0.005, acc: 1.000: 100%|██████████| 329/329 [00:10<00:00, 31.11it/s]\n",
      "[valid epoch 229] loss: 0.558, acc: 0.866: 100%|██████████| 313/313 [00:03<00:00, 88.32it/s] \n"
     ]
    }
   ],
   "source": [
    "val_l = []\n",
    "val_pre = []\n",
    "val_ac = []\n",
    "val_path = []\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    accu_loss = torch.zeros(1).to(device)  # 累计损失\n",
    "    accu_num = torch.zeros(1).to(device)  # 累计预测正确的样本数\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    sample_num = 0\n",
    "    data_loader = tqdm(train_loader)\n",
    "    for step, data in enumerate(data_loader):\n",
    "        images, labels, p = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        sample_num += images.shape[0]\n",
    "\n",
    "        pred = model(images.to(device))\n",
    "        \n",
    "        pred_classes = torch.max(pred, dim=1)[1]  # 预测的类别，[1]是标签索引\n",
    "       \n",
    "        \n",
    "        accu_num += torch.eq(pred_classes, labels.to(device)).sum()\n",
    "        loss = loss_function(pred, labels.to(device))\n",
    "        loss.backward()\n",
    "        \n",
    "        accu_loss += loss.detach()\n",
    "        \n",
    "        data_loader.desc = \"[train epoch {}] loss: {:.3f}, acc: {:.3f}\".format(epoch,\n",
    "                                                                               accu_loss.item() / (step + 1),\n",
    "                                                                               accu_num.item() / sample_num)\n",
    "        optimizer.step()  # 更新\n",
    "\n",
    "    train_loss =  accu_loss.item() / (step + 1)\n",
    "    train_acc = accu_num.item() / sample_num\n",
    "    val_loss, val_acc, paths, ls, pres, acs = utils.evaluate_save(model=model,\n",
    "                                data_loader=val_loader,\n",
    "                                device=device,\n",
    "                                epoch=epoch,\n",
    "                                save=True)\n",
    "    val_path = paths\n",
    "    val_pre.append(pres)\n",
    "    val_ac.append(acs)\n",
    "    val_l = ls\n",
    "    # writer.add_scalar(tags[0], train_loss, epoch)\n",
    "    # writer.add_scalar(tags[1], train_acc, epoch)\n",
    "    # writer.add_scalar(tags[2], val_loss, epoch)\n",
    "    # writer.add_scalar(tags[3], val_acc, epoch)\n",
    "    # writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)\n",
    "    \n",
    "    \n",
    "    scheduler.step()\n",
    "    if save:\n",
    "        if epoch < 40:\n",
    "             \n",
    "            state = {\n",
    "                    'epoch' : epoch + 1,  #保存当前的迭代次数\n",
    "                    'state_dict' : model.state_dict(), #保存模型参数\n",
    "                    'optimizer' : optimizer.state_dict()\n",
    "                }\n",
    "\n",
    "            torch.save(state, './weights_LDA/checkpoint-' + str(epoch+1) + '.pth.tar')  \n",
    "        \n",
    "        if (epoch + 1)%10 == 0 and epoch > 40:\n",
    "            state = {\n",
    "                    'epoch' : epoch + 1,  #保存当前的迭代次数\n",
    "                    'state_dict' : model.state_dict(), #保存模型参数\n",
    "                    'optimizer' : optimizer.state_dict()\n",
    "                }\n",
    "\n",
    "            torch.save(state, './weights_LDA/checkpoint-' + str(epoch+1) + '.pth.tar')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_pre = np.array(val_pre).T\n",
    "val_ac = np.array(val_ac).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vals = []\n",
    "for index, p in enumerate(val_path):\n",
    "    data = {}\n",
    "    data[\"path\"] = p\n",
    "    data[\"label\"] = val_l[index].item()\n",
    "    data[\"pre\"] = val_pre[index].tolist()\n",
    "    data[\"acc\"] = val_ac[index].tolist()\n",
    "    vals.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./train_detail/val_data_resnet18.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.dump(vals, f, allow_unicode=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac2c9fc71220d1b58b3640599b1e22027da1326aa67720425adf09ad6c638495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}